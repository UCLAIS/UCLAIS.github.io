"use strict";(self.webpackChunkucl_artificial_intelligence_society=self.webpackChunkucl_artificial_intelligence_society||[]).push([[1477],{10:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"nobel-prizes-2024","metadata":{"permalink":"/blog/nobel-prizes-2024","source":"@site/blog/2024-10-20-nobel-prizes-2024.md","title":"AI and the Protein Revolution: Reshaping Our Future","description":"Demis Hassabis, CEO of DeepMind, junior chess prodigy, former game developer and, of course, UCL alumnus, made headlines last week by joining the ranks of Nobel Laureates in Chemistry. He and his colleague, John M. Jumper, senior science researcher at DeepMind, achieved a game-changing breakthrough by pioneering new methods for predicting protein structures with Artificial Intelligence, and were awarded the half the Nobel Prize for their efforts.\u200b","date":"2024-10-20T00:00:00.000Z","formattedDate":"October 20, 2024","tags":[{"label":"nobel prize","permalink":"/blog/tags/nobel-prize"},{"label":"chemistry","permalink":"/blog/tags/chemistry"}],"readingTime":3.565,"hasTruncateMarker":false,"authors":[{"name":"Sofiya Flenova","title":"Content Executive","imageURL":"/img/committee/sofiya_flenova.jpeg","key":"sofiya"}],"frontMatter":{"slug":"nobel-prizes-2024","title":"AI and the Protein Revolution: Reshaping Our Future","subtitle":"Reshaping Our Future","authors":["sofiya"],"tags":["nobel prize","chemistry"]},"nextItem":{"title":"Welcome (or Welcome Back)","permalink":"/blog/reintroductions"}},"content":"**Demis Hassabis**, CEO of DeepMind, junior chess prodigy, former game developer and, of course, UCL alumnus, made headlines last week by joining the ranks of Nobel Laureates in Chemistry. He and his colleague, **John M. Jumper**, senior science researcher at DeepMind, achieved a game-changing breakthrough by pioneering new methods for predicting protein structures with Artificial Intelligence, and were awarded the half the Nobel Prize for their efforts.\u200b\\n\\nAlong with that, **David Baker**, professor of biochemistry and Director of the Institute for Protein Design at the University of Washington has been awarded the other half of the 2024 Nobel Prize in Chemistry for computational protein design.\\n\\nThese breakthroughs introduce us to a golden era of science and completely rewrite our future. And here\'s why we must talk about it. \\n\\n### David Baker\\n\\n*\u201cIn nature, proteins are the miniature machines that carry out all the important jobs: we can think, we can move, we can digest food, plants can capture energy from the sunlight and everything that happens in the living organism is due to proteins. We can use proteins to solve problems that evolution did not manage to solve.\u201d* - David Baker.\\n\\nEach protein chain folds into its own characteristic shape and the folding process is very precise. The shape of a folded protein chain is what defines its biological functions. However, there are so many different shapes a protein can adopt, which made the protein problem so difficult and rendered it unsolved for over 50 years. Up until now. \\n\\nThe gigantic increase in computing power since the problem\u2019s discovery now enables us to design tens of thousands of new proteins with new shapes and new functions. There are now over 10<sup>130</sup> different designs we can explore using computation, enormously larger than the total number of proteins that have existed since life on earth began. After creation, we can  extract the proteins, and then determine their functions and whether they are safe. \\n\\nToday we face challenges such as serious ecological threats as well as new diseases evolving, and we do not have millions of years to wait for the discovery of the right proteins. But using computational design tools, we can now build these completely new multi-purpose proteins. \\n\\n### John M. Jumper and Demis Hassabis\\n\\nThe AI system *AlphaFold2* by DeepMind is the first non-experimental method that can predict the complex structure of any known protein in nature, also solving the \\"50-year grand challenge\\", in the words of Hassabis himself. This system can predict the way a protein folds based on the amino acid sequence it consists of, which enables us to create proteins that can perform very specific functions and help us drive humanity\'s development. \\n\\nUntil very recently it could take research biologists a year to get a single answer about a 3D shape of a protein fold; now we have a machine learning algorithm that can do the same in 5-10 minutes. \\n\\n![Alt text](/img/blog/nobel-prize-1.png)\\n\\nThe program consists of three stages: database search and preprocessing, *EvoFormer*, and structure model. \\n\\n**Database search and preprocessing.** A sequence of amino acids is entered, and *AlphaFold* compares it to records from several databases to extract similar sequences from other organisms. It also creates a pair representation of this input sequence, showing pairs of amino acid residues that are close together in 3D space within the target protein. Residue is the part of an amino acid that remains after it forms a peptide chain with other amino acids, and water is removed.\\n\\n***EvoFormer*** is a unique *AlphaFold* neural network that looks for relationships in residue pairs of the input sequence. It also evaluates the relationship within any two residues, which can be thought of as nodes in NNs. These calculations are carried out 48 times before forming a refined model of residue pair representations. \\n\\nFinally, **the Structure Model** is another neural network that takes the previously refined model and performs rotation and translation on it to create a prediction of what its 3D protein structure looks like.\\n\\nThese newly developed proteins can fight cancer, break down plastic waste, and develop vaccines for respiratory diseases among many other uses. This intersection of biology and AI in 2024 can help us uncover the secrets of life, fight diseases, and even address the overwhelming climate challenges of today and the future."},{"id":"reintroductions","metadata":{"permalink":"/blog/reintroductions","source":"@site/blog/2024-10-01-reintroductions.md","title":"Welcome (or Welcome Back)","description":"Welcome (or welcome back) to UCL Artificial Intelligence Society\u2019s blog!","date":"2024-10-01T00:00:00.000Z","formattedDate":"October 1, 2024","tags":[{"label":"welcome","permalink":"/blog/tags/welcome"},{"label":"introductions","permalink":"/blog/tags/introductions"},{"label":"events","permalink":"/blog/tags/events"},{"label":"miniblog","permalink":"/blog/tags/miniblog"}],"readingTime":1.49,"hasTruncateMarker":false,"authors":[{"name":"Anthony Nkyi","title":"Head of Content","imageURL":"/img/committee/anthony_nkyi.jpeg","key":"anthony"}],"frontMatter":{"slug":"reintroductions","title":"Welcome (or Welcome Back)","authors":["anthony"],"tags":["welcome","introductions","events","miniblog"]},"prevItem":{"title":"AI and the Protein Revolution: Reshaping Our Future","permalink":"/blog/nobel-prizes-2024"},"nextItem":{"title":"Is AI an existential risk?","permalink":"/blog/ai-safety-debate"}},"content":"## Welcome (or welcome back) to UCL Artificial Intelligence Society\u2019s blog!\\n\\nI\u2019m Anthony, the new Head of Content, and I just can\u2019t wait for everything we\u2019ve got planned for UCL AI Society this year. \\n\\nThe year ahead is looking exciting \u2013 there\u2019s a lot going on. We have the return of our incredible initiatives. We\u2019re getting a new season of Reinforcement Talking, the UCL AI Society podcast **(episode coming out VERY soon)**. And of course, our brilliant *blog* is back for another year. In this mini-update, I\'m going to walk you through what\'s happening in the coming days and weeks. \\n\\n## What\'s on?\\n\\n**Tutorials** are back, where you can learn how to code a vast range of machine learning techniques, completely free for our members. It\'s every Wednesday, open to all ranges of abilities, so get it onto your calendars.\\n\\nThen we have **Nexus Labs**, where you can put these skills to work on a research project, exploring one of neuroscience, robotics, GenAI, practical AI, or responsible AI, culminating in an epic symposium where you can present your findings.\\n\\nFor the visionaries and entrepreneurs amongst our membership (yes, get yours now if you haven\u2019t), you can apply to **AI Foundry**, which provides you with a series of workshops, mentoring opportunities, and chances to pitch your brainchildren to keen investors, and industry experts. \\n\\nFinally, **Journal Clubs** invite some of the world\u2019s greatest minds in AI for live and exclusive talks about their research \u2013 we\u2019ve hosted individuals from top institutions across the globe talking about everything between machine learning theory and its applications.\\n\\nThat\u2019s not just it though. We\u2019ve got hackathons coming up, some big events, career panels, and more\u2026 but stay updated through this blog and our members\u2019 newsletter to hear about these as soon as they\u2019re confirmed."},{"id":"ai-safety-debate","metadata":{"permalink":"/blog/ai-safety-debate","source":"@site/blog/2024-03-17-ai-safety-debate.md","title":"Is AI an existential risk?","description":"AI Safety Debate","date":"2024-03-17T00:00:00.000Z","formattedDate":"March 17, 2024","tags":[{"label":"ai safety","permalink":"/blog/tags/ai-safety"},{"label":"debate","permalink":"/blog/tags/debate"}],"readingTime":5.51,"hasTruncateMarker":false,"authors":[{"name":"Charlie Harrison","title":"Head of Content","imageURL":"/img/committee/charlie_harrison.jpg","key":"charlie"}],"frontMatter":{"slug":"ai-safety-debate","title":"Is AI an existential risk?","authors":["charlie"],"tags":["ai safety","debate"]},"prevItem":{"title":"Welcome (or Welcome Back)","permalink":"/blog/reintroductions"},"nextItem":{"title":"Welcome to the UCL AI Society","permalink":"/blog/welcome"}},"content":"## AI Safety Debate\\n\\nIt was a real privilege to host, alongside two of the best societies at UCL \u2013 AI Society, and UCL Effective Altruism \u2013 our AI Safety Debate, on the topic of, \u201cIs AI an existential risk?\u201d\\n\\n\ud83c\udfac A full recording can be found [here](https://www.youtube.com/watch?v=mcozzJbLbZI), if you want to watch the whole thing.\\n\\n### Why talk about AI safety?\\n\\nI believed it was important to host this debate because I think this question is, potentially, highly important, but also, one which I have deep uncertainties about. Many AI experts like Geoffrey Hinton think that AI should be considered just as risky as pandemics or nuclear war, and that we need to slow down, or pause its development. Others, like Melanie Mitchell, believe that the risks are \u201calmost vanishingly small\u201d. The stakes of the question for humanity warrant a serious (and long, in my opinion) conversation about the respective arguments\u2019 merits.\\n\\nAfter this prelude, my wonderful colleagues Ivana and Maja introduced the speakers. We were lucky enough to have [Reuben Adams](https://www.linkedin.com/in/reuben-adams-10031b180/?originalSubdomain=uk) and [Chris Watkins](https://www.cs.rhul.ac.uk/~chrisw/) arguing for the \u201cdoomer\u201d side (as we referred to it, in the WhatsApp group chat). Reuben is a UCL AI PhD student, and host of the wonderful [\u2018Steering AI\u2019 Podcast](https://www.ucl.ac.uk/ai-centre/steering-ai-podcast). Chris is a professor at Royal Holloway, and a prominent thinker in the \u2018Reinforcement Learning\u2019 field. For the \u2018risk-skeptical side\u2019 (the \u2018anti-doomer\u2019 side??), was [Jack Stilgoe](https://www.linkedin.com/in/jack-stilgoe-2a6187a/?originalSubdomain=uk) and [Kenn Cukier](https://www.linkedin.com/in/kenneth-cukier-9ab56335/?originalSubdomain=uk). Jack is a UCL professor, on \u201chome-turf\u201d as he said, lecturing in Science and Technology Studies (STS), and works closely with UK Research and Innovation on the \u201cResponsible AI Program\u201d. Kenn is a Deputy Executive Editor at The Economist magazine, and hosts the weekly tech podcast, \u201cBabbage\u201d . [Tom Ough](https://uk.linkedin.com/in/tomough), a freelance journalist, who\u2019s written various pieces about existential risk, including in Prospect Magazine, was moderating. Ivana encouraged our audience to consider how the lack of demographic diversity on the panel could systematically bias the conversation, which (as you\u2019ll read) came up in discussions.\\n\\nAt face value, the 4 speakers seemed to argue distinctly opposing points of view. I will briefly give my best effort at summarizing their views, in the order in which they spoke. After, I look to set out promising areas of agreement amongst all the panelists.\\n\\n### The debate\\n\\nReuben opened the debate. He argued that the new paradigm of deep-learning presents a distinctly new category of AI risk: we are building ever-more intelligent \u2018black-boxes\u2019, with novel capabilities we cannot predict. Once there is a \u201csecond species of intelligence\u201d that rivals our own, we are completely ignorant about what will follow. Our current tools for controlling AI systems, like \u2018RLHF\u2019, are woefully inadequate even at present, and won\u2019t \u2018scale up\u2019 with increasing AI progress. What follows from all this? \u201cI don\u2019t understand how you can confidently say that this doesn\u2019t end badly.\u201d\\n\\nAfter Reuben, came Jack. He eased his way into his argument with several cool anecdotes. (From Reuben\u2019s speech, the day after Earnest Rutherford denied the feasibility of nuclear energy, in September 1933, Leo Szilard conceived of the nuclear chain reaction. Jack said that the concept came to Szilard by Russell Square Station. Go there if you want to conceive of the next big thing). Anyway. Back to the seriousness. Rogue AI scenarios are implausible and belong in science fiction. Instead, \u201cthe idea of existential risk from AI is a form of displacement activity\u201d, from other more pressing concerns, like the disempowerment of workers or marginalization of minorities. These are the risks that deserve regulators\u2019 attention. A more interesting question, for Jack, is why people are drawn towards believing these risks: perhaps peoples\u2019 positionality, or for some technologists their self-interest. AI is a tool like any other, in that it\u2019s \u201call about power\u201d, so \u201cwe shouldn\u2019t be worrying about what robots will do to humanity, instead we should worry about what some people will do to other people\u201d.\\n\\nAfter Jack, there was Chris. From his perspective, the algorithmic breakthroughs that enabled ChatGPT are pedestrian. His MSc students are already implementing the \u201ctransformer\u201d architecture for their coursework, the major breakthrough behind large language models like ChatGPT. Given that tens of thousands of people and 11 figure sums are being directed towards AI, we have no reason to believe that further breakthroughs won\u2019t occur. Instead, we should expect a future of open-ended cognitive advancement. This unknowable future is \u201cbehind a veil\u201d. While we aren\u2019t necessarily destined for doom, there are plausible \u201cside-roads\u201d that lead towards it, in particular AI-enabled authoritarian regimes.\\n\\nFinally, it was Kenn\u2019s turn. \u201cThis is bleak!\u201d, he started with. Whilst the risks from AI are serious, they won\u2019t scale to an \u2018existential catastrophe\u2019. Existing alignment techniques like RLHF put humans in the loop, and will obstruct any \u2018intelligence explosion\u2019. Humans are unlikely to cede control of political power or nuclear missile systems to AI. Among different possible futures, we can design \u201clove\u201d into AI. In contrast, misuse risks do seem concerning. Kenn was anxious when news broke in 2022 that AI had developed 40,000 toxic chemicals in 6 hours. However, there is nuance here. The threat model of \u2018misuse risks\u2019 from bad actors already exists today. Lethal Autonomous Weapons may make warfare less brutal. So, let\u2019s not be defeatist, and instead focus on \u201cexistential solutions\u201d.\\n\\n### (Dis)agreements!\\n\\nA key disagreement for the participants seemed to be: Reuben and Chris seemed to acknowledge that exact pathways to catastrophe are unknowable \u2013 and would be analogous to bonobos trying to predict how they would be outcompeted by humans. Kenn, and particularly Jack, emphasized this point, and suggested that the \u2018rogue AI story\u2019 parallels science fiction. Reuben/Chris seem to bite the bullet.\\n\\nHowever, amongst these disagreements, there were several areas of agreement, which questions from our moderator, Tom, helped to elucidate:\\n\\n- Proactive oversight/regulation of AI systems today is necessary to guard against present-day harms, like misinformation.\\n- Careful evaluations of AI models is an area of potential common ground between those concerned about \u2018near-term\u2019 and \u2018long-term risks\u2019 from AI.\\n- AI represents a new (potentially transformative) era for humanity\\n- Predicting exactly how the future will unfold is nigh on impossible; speculation about how exactly AI harms might scale to catastrophe or even extinction is very difficult to conceive precisely.\\n- AI is likely to be a \u201cforce-multiplier\u201d and may enable bad actors to do worse things\\n\\nOn these points, and others, I think the speakers realized that their worldviews were closer than they might have expected.\\n\\nI am very grateful to Ivana, Maja, Asmita for helping with the organizing of the event, and to Andrzej and Yadong for helping with the filming."},{"id":"welcome","metadata":{"permalink":"/blog/welcome","source":"@site/blog/2023-08-30-welcome.md","title":"Welcome to the UCL AI Society","description":"Hello and welcome to the very first UCL AI Society blogpost of the year!","date":"2023-08-30T00:00:00.000Z","formattedDate":"August 30, 2023","tags":[{"label":"welcome","permalink":"/blog/tags/welcome"}],"readingTime":3.825,"hasTruncateMarker":false,"authors":[{"name":"Martynas Pocius","title":"President","imageURL":"/img/committee/martynas_pocius.jpg","key":"martynas"},{"name":"Jess Tsang","title":"Event Officer","imageURL":"/img/committee/jessica_tsang.JPG","key":"jess"}],"frontMatter":{"slug":"welcome","title":"Welcome to the UCL AI Society","authors":["martynas","jess"],"tags":["welcome"]},"prevItem":{"title":"Is AI an existential risk?","permalink":"/blog/ai-safety-debate"}},"content":"## Hello and welcome to the very first UCL AI Society blogpost of the year!\\n\\nMy name is Jessica and I\u2019m so excited to be your Creative Director this year \ud83d\ude04, You\u2019ll be hearing from me every week about **the AI buzz and news on the society**, and **any upcoming events** you should bookmark in your calendar, so be sure to keep your eyes peeled on the society blog to stay updated \ud83d\udcda\ufe0f.\\n\\nWith the introductions out of the way, today\u2019s blog post is for all our new members and getting you up-to-date on what this is all about. First of all, massive congratulations on getting into UCL! That is no small feat, and we\u2019re so glad you were able to join us in not-so-sunny London \ud83c\udf27\ufe0f (it gets better in February, trust). Secondly, congratulations on having excellent taste in societies, and frankly, joining the best one out there. We promise you\u2019re going to have a good time.\\n\\nSince our inception, the UCL AI Society has grown massively, and we\u2019re proud to say that we are one of the most prolific student societies at UCL. We\u2019d like to think it\u2019s because we have something for everyone, even for those who aren\u2019t compsci students or know how to code! Artificial intelligence is something that will affect everyone in the years to come, regardless of who you are, and as a result, we believe our society should be accessible and relevant to all pathways and disciplines. We hope the AI society can be your place to explore your interests, build long-lasting relationships and make memories for life. Some of the social events you can get involved in are our iconic Thursday Pizza Socials \ud83c\udf55 (free pizza for all!), speaker events with world-renowned researchers \ud83e\uddd1\u200d\ud83c\udfeb, tutorials \ud83d\udcbb\ufe0f, cross-university networking events \ud83e\uddd1\u200d\ud83e\udd1d\u200d\ud83e\uddd1, and more.\\n\\nWe also have programs running on a larger scale for those of you who want to improve your own skills, dip into research or begin a start-up. For research, we have the Nexus Labs project \ud83e\uddd1\u200d\ud83d\udcbb, which is an interdisciplinary initiative for students to engage in one of five academic pillars: Neuroscience, NLP, Finance, Machine Vision and Responsible AI \u270f\ufe0f. Within each pillar, teams will have a specialist on board to explore a question with the aim of publishing a research paper at the end of the project.\\n\\nFor those of you wanting to explore the world of entrepreneurship, we have the UCL AI Foundry \ud83d\udcc8, our incubator for budding AI businesses. Upon joining Foundry, you\u2019ll be given guidance, support and advice throughout the project from assigned mentors. At the end, you\u2019ll be given an opportunity to pitch your start-up to a panel of investors who can help your business take off.\\n\\nAnd finally, our biggest event of the year: ClimateHack.AI \ud83c\udf0e\ufe0f, our society hackathon which brings together 25 leading universities to solve some of our climate\u2019s most pressing problems.\\n\\nThis year, ClimateHack.AI is helping to solve the issue of solar nowcasting \u2600\ufe0f, essentially helping us optimise solar panels as solar power is highly variable considering weather conditions. By building better solar photovoltaic nowcasting, we\u2019re able to help derisk the deployment of solar power and encourage its use in energy grids around the world. In the UK alone, this could help us reduce 100,000 tonnes of carbon emissions. Around the world, there would be a reduction of 50 to 100 million tonnes of carbon.\\n\\nFor ClimateHack.AI 2022, we focused on satellite imagery nowcasting \ud83d\udef0\ufe0f and managed to build a model 3.5x more accurate than the one being used by the National Grid Electricity System Operator (NG-ESO). As a result, we know the impact ClimateHack.AI has, and we\u2019ve seen the good it can do. For ClimateHack.AI 2023, we encourage you to participate if this is something that catches your eye! We can\u2019t make a tangible impact without your help, and the hackathon has been some of our previous members\u2019 favourite part of the society, so we guarantee it\u2019ll be a good time. You\u2019ll be able to meet like-minded individuals, expand your network and career opportunities, and have a shot at our prize pool with a grand first prize of \xa315,000 \ud83d\udcb0\ufe0f!\\n\\nUltimately, as you can probably see, UCL AI Society is packed full of different events happening every week, and as your committee, we\u2019re dedicated to making sure this society provides everything possible to help you thrive both personally and professionally \ud83e\udee1. Regardless, we hope we\u2019ll see you in some of these events once the school year starts up, and as always, feel free to reach out with any questions.\\n\\nSee you next week! \ud83d\udc4b\\n\\nJessica"}]}')}}]);