<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>UCL Artificial Intelligence Society Blog</title>
        <link>https://uclaisociety.co.uk/blog</link>
        <description>UCL Artificial Intelligence Society Blog</description>
        <lastBuildDate>Fri, 07 Mar 2025 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The Undead Internet]]></title>
            <link>https://uclaisociety.co.uk/blog/undead-internet</link>
            <guid>https://uclaisociety.co.uk/blog/undead-internet</guid>
            <pubDate>Fri, 07 Mar 2025 00:00:00 GMT</pubDate>
            <description><![CDATA["They look like people, they act like people, but there are no people left. Well, there's you and maybe a few others, but you can't tell the difference, because the bots wear a million masks." - Robert Mariani, The Dead Internet to Come.]]></description>
            <content:encoded><![CDATA[<p><em>"They look like people, they act like people, but there are no people left. Well, there's you and maybe a few others, but you can't tell the difference, because the bots wear a million masks."</em> - Robert Mariani, The Dead Internet to Come.</p><p>Bots are everywhere on the Internet. I’m sure you’ve noticed them selling concert tickets in your WhatsApp chats, popping up on customer support websites, replying to your tweets (X posts now?) with ostensibly human-like parlance. They don’t seem to be going anywhere, and that’s a problem.</p><p>Take the social media platform X. The <a href="https://mashable.com/article/x-twitter-elon-musk-bots-fake-traffic" target="_blank" rel="noopener noreferrer">number of botted accounts on there has exploded since the October 2022 buyout by Elon Musk</a>, despite his promises to eliminate them. And they’re smarter than ever now. No more hashtag spamming and non sequiturs. They’re contributing to legitimate conversations, <a href="https://globalwitness.org/en/campaigns/digital-threats/no-ifs-many-bots-partisan-bot-like-accounts-continue-to-amplify-divisive-content-on-x-generating-over-4-billion-views-since-the-uk-general-election-was-called/" target="_blank" rel="noopener noreferrer">(not always with good intentions)</a>, garnering interactions and attention from humans and other bots alike. ChatGPT was its printing press.</p><p>One social media platform wouldn’t be a big issue. But generative AI (genAI) results <a href="https://futurism.com/pinterest-ai-slop" target="_blank" rel="noopener noreferrer">on Pinterest</a> too? Fake true crime documentaries on YouTube? Strange image search results? <a href="https://futurism.com/sports-illustrated-ai-generated-writers" target="_blank" rel="noopener noreferrer">Then even sports journalism?</a></p><p>Doctor Who fans reading this blog may recall the second episode of its 2005 reboot, in which the Ninth Doctor and Rose Tyler visit the Earth minutes before it is due to be engulfed by the red giant Sun. On their space station, the “Last Human” attempts to pull off an insurance scam by arresting the ship with robotic spiders, hidden in gifts offered by her servient robots, the Adherents of the Repeated Meme. (By the way, the “Last Human” is really a 2000-year-old skin graft and was granted that name based on being the last born of two full humans, around 5 billion years into the future.)</p><p>Mapped literally, we already see internet entertainment such as memes heading this direction. Of course, let people enjoy things…</p><p>…but I do find it interesting how easy it is for meta-posting and “brainrot” to spread as far as mainstream culture. The jokes are easy to make – in fact, the joke is the fact that it’s a joke, by some tautology. Give a model a database of viral tweets, common tropes, some Druski and LeBron gifs, and you’ll probably be looking at a 100k-like TikTok post in a few hours. A personal favourite of mine has got to be @multimedia2012. Whether or not that account steal posts from X and Facebook then packages it up a genAI video of that scenario, its TikToks are unfortunately quite funny.</p><p>Back to the bigger picture. I see that episode’s parallels in how actual human users employ genAI. Churning out such content further pollutes the sea of information noise that is the modern Internet, making it substantially more difficult to fish out unique content. And to reiterate the common point, you are damaging creative integrity, especially if used where the human touch is expected.</p><p>The honest, carefree Internet as we knew it is dead. Yet, we, out of ignorance or insanity, have replaced the robots that killed it by creating freakish cyborg-zombies from what we once despised.</p><p>As the phrase goes, the only thing worse than flogging a dead horse is betting on one. There doesn’t seem to be anyone left to stop us going all-in.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="further-reading">Further reading<a href="#further-reading" class="hash-link" aria-label="Direct link to Further reading" title="Direct link to Further reading">​</a></h3><p>R. Mariani, “The Dead Internet to Come,” The New Atlantis, vol. 73, no. 73, pp. 34–42, 2023, doi: <a href="https://doi.org/10.2307/27244117" target="_blank" rel="noopener noreferrer">https://doi.org/10.2307/27244117</a>.</p><p>A. Hern, “TechScape: On the internet, where does the line between person end and bot begin?,” The Guardian, Apr. 30, 2024. Available: <a href="https://www.theguardian.com/technology/2024/apr/30/techscape-artificial-intelligence-bots-dead-internet-theory" target="_blank" rel="noopener noreferrer">https://www.theguardian.com/technology/2024/apr/30/techscape-artificial-intelligence-bots-dead-internet-theory</a></p>]]></content:encoded>
            <category>internet</category>
            <category>bots</category>
            <category>social media</category>
            <category>dead internet theory</category>
        </item>
        <item>
            <title><![CDATA[The First Neural Network: Foundations of Modern AI]]></title>
            <link>https://uclaisociety.co.uk/blog/first-neural-network</link>
            <guid>https://uclaisociety.co.uk/blog/first-neural-network</guid>
            <pubDate>Sun, 02 Mar 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[Neural networks have shaped the way we interact with the world. From the deep learning technologies behind self-driving cars to the Natural Language Processing enhancements that power intelligent systems, neural networks are at the forefront of modern AI. But to truly appreciate the deep learning applications we use today, it’s important to examine the foundational theories that lay the groundwork for the field. By first looking at what a neural network is and then exploring the concepts underlying McCulloch and Pitts' theoretical neural network design, we can better appreciate the ingenuity of the technology that has transformed modern AI.]]></description>
            <content:encoded><![CDATA[<p>Neural networks have shaped the way we interact with the world. From the deep learning technologies behind self-driving cars to the Natural Language Processing enhancements that power intelligent systems, neural networks are at the forefront of modern AI. But to truly appreciate the deep learning applications we use today, it’s important to examine the foundational theories that lay the groundwork for the field. By first looking at what a neural network is and then exploring the concepts underlying McCulloch and Pitts' theoretical neural network design, we can better appreciate the ingenuity of the technology that has transformed modern AI.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-a-neural-network">What is a Neural Network?<a href="#what-is-a-neural-network" class="hash-link" aria-label="Direct link to What is a Neural Network?" title="Direct link to What is a Neural Network?">​</a></h3><p>A neural network is a computational model inspired by the structure of the brain. Neural networks typically consist of layers of nodes, or artificial neurons—an input layer, one or more hidden layers, and an output layer—connected to each other in a way that mimics the interconnected nature of neurons in the brain. Each node has its own weight and threshold associated with it. If the output of any individual node is above the specified threshold value, it becomes activated, passing information to the next layer. The network "learns" by adjusting the weights of these connections through a process called backpropagation, which minimizes errors over multiple training iterations.</p><p>Modern neural networks are complex multi-layered networks capable of solving intricate tasks like image recognition, natural language processing, and autonomous driving. They have had a profound impact on modern technology, revolutionizing and enriching people's lives through their application in solutions ranging from large language models like GPT-4 to advancements in healthcare, such as disease detection and drug discovery.</p><p><img loading="lazy" alt="How an artificial neural network works: input layer, hidden layers, output layers. (Image source: Facundo Bre)" src="/assets/images/neural-network-1-e83cbc25d063256bf50750632f165e80.png" width="850" height="498" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-turing-machine">The Turing Machine<a href="#the-turing-machine" class="hash-link" aria-label="Direct link to The Turing Machine" title="Direct link to The Turing Machine">​</a></h3><p>To truly appreciate modern neural networks, it’s important to look at the story of their first theoretical inception. The origins of neural networks are intertwined with the origins of artificial intelligence itself, beginning in Cambridge in 1936, where a mathematician named Alan Turing was quietly laying the foundation for modern AI.</p><p>In 1936, Turing was tasked with the <em>Entscheidungsproblem</em>, a question posing whether there is an algorithm that can determine the truth or falsity of any statement within a specified system. To prove that no such algorithm exists for sufficiently complex systems, Turing invented a theoretical problem-solving machine called a Turing Machine. A Turing Machine consists of an infinite tape divided into cells, a head that can read and write symbols on the tape, and a set of rules. The machine operates by moving the head along the tape, reading symbols, and following the rules to write new symbols and move left or right, allowing it to simulate any algorithm given to it.</p><p>Using this, he answered the <em>Entscheidungsproblem</em> by proving that no algorithm can universally decide whether an arbitrary Turing machine will halt or run forever on a given input. This became known as the Halting Problem, which he detailed in his 1936 paper <em>“On Computable Numbers, with an Application to the Entscheidungsproblem.”</em> Turing’s insight—that any computable function could be broken down into simple operations through reading and writing symbols on an infinite tape—was a revolutionary idea that sparked the development of all artificial intelligence fields that followed.</p><p><img loading="lazy" alt="The Universal Turing machine: complete with Turing Machine descriptions, tape, and transitions. (Image source: MIT)" src="/assets/images/neural-network-2-650b7449b5359b2c7c8e48c60581eadc.gif" width="516" height="208" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-first-neural-network">The First Neural Network<a href="#the-first-neural-network" class="hash-link" aria-label="Direct link to The First Neural Network" title="Direct link to The First Neural Network">​</a></h3><p>Inspired by Turing’s 1936 paper, Warren McCulloch, a neuroscientist, and Walter Pitts, a logician, published their influential 1943 paper <em>"A Logical Calculus of the Ideas Immanent in Nervous Activity"</em> in which they explored how the brain might perform computations. Turing’s paper provided a theoretical basis for thinking of computation in strictly formal terms and had shown that any computable function could be realized by a Turing machine. Pitts and McCulloch saw a parallel between Turing’s machine and the way groups of neurons might process and transmit information.</p><p>They proposed that neurons could be modeled as binary on-off units, firing when inputs exceeded a certain threshold (akin to receiving enough excitatory signals). By connecting these idealized neurons in various configurations, they demonstrated that the systems could implement basic logical operators like AND, OR, and NOT. This offered the possibility that these systems might simulate logical operations or even more complex computations. They were the first to describe what later researchers would call a neural network.</p><p><img loading="lazy" alt="The McCulloch-Pitts Neuron Model. (Image source: available under fair use, Creative Commons)" src="/assets/images/neural-network-3-9a0df51c84f2d8c7b6b47b142b9f2ba9.png" width="850" height="367" class="img_ev3q"></p><p>Although their model was only theoretical and faced several limitations, their mathematical approach to neural functioning inspired subsequent generations of researchers—paving the way for cybernetics and later the field of artificial intelligence. Their work ultimately shaped the path for modern AI and deep learning, which are now deeply embedded in our everyday lives.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References">​</a></h3><p>A. Turing, “On Computable Numbers, with an Application to the Entscheidungsproblem,” 1936. Available: <a href="https://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf" target="_blank" rel="noopener noreferrer">https://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf</a>.</p><p>W. S. Mcculloch and W. Pitts, “A LOGICAL CALCULUS OF THE IDEAS IMMANENT IN NERVOUS ACTIVITY*,” Bulletin of Mathematical Biology, vol. 52, no. 2, pp. 99–115, 1943, Available: <a href="https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf" target="_blank" rel="noopener noreferrer">https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf</a>.</p>]]></content:encoded>
            <category>history</category>
            <category>neural networks</category>
            <category>turing</category>
            <category>deep learning</category>
        </item>
        <item>
            <title><![CDATA[The Intelligence Race: Now and Then]]></title>
            <link>https://uclaisociety.co.uk/blog/how-ww2-shaped-ai</link>
            <guid>https://uclaisociety.co.uk/blog/how-ww2-shaped-ai</guid>
            <pubDate>Tue, 28 Jan 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[New “modern intelligence” technologies such as signals, telegraphy, and radios emerged at the beginning of the 20th century. They quickly became indispensable, especially in wartime, where they gave significant strategic advantages to military forces. But until recently, we underappreciated the significance of the once-obscure role intelligence played in WW2, especially for the “Big Four” Allies (the United States, Soviet Union, United Kingdom and China).]]></description>
            <content:encoded><![CDATA[<p>New “modern intelligence” technologies such as signals, telegraphy, and radios emerged at the beginning of the 20th century. They quickly became indispensable, especially in wartime, where they gave significant strategic advantages to military forces. But until recently, we underappreciated the significance of the once-obscure role intelligence played in WW2, especially for the “Big Four” Allies (the United States, Soviet Union, United Kingdom and China).</p><p><strong>‘Often intelligence is a winning factor.” - John Ferris, The Cambridge History of the Second World War.</strong></p><p>However, the most interesting take-away is that technologies born of the war planted the seed for Artificial Intelligence as a concept. The appearance of AI can be traced back to the work of cryptographers during World War II, who used early computing machines to crack military codes. The appearance of AI can be traced back to the work of cryptographers during World War II, who used early computing machines to crack military codes.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-enigma-and-the-bombe">The Enigma and the Bombe<a href="#the-enigma-and-the-bombe" class="hash-link" aria-label="Direct link to The Enigma and the Bombe" title="Direct link to The Enigma and the Bombe">​</a></h3><p>Every country involved in World War II had to encode its military communication to protect vital information from enemy forces. The Enigma Machine used by the Germans at that time was an electromechanical device used to encrypt and decrypt messages. Operators would input plaintext messages on the keyboard, and the machine would encipher the message by illuminating a corresponding letter. The encoded message would then be transmitted, typically via radio. The algorithm would constantly change, so each keystroke would result in a new encryption pattern, which made the Enigma especially complex to crack. </p><p>To counteract Enigma algorithms, the brilliant minds at Bletchley Park, including now-renowned Alan Turing developed the Bombe. The Bombe was designed to automate the process of testing possible Enigma rotor configurations to deduce the daily settings. It worked by going through millions of rotor settings of the Enigma machine to determine which composition was used to encrypt a message. </p><p>But how was this code-breaking machine a predecessor to modern AI?</p><p><img loading="lazy" alt="The Enigma machine" src="/assets/images/history-of-ai-1-ac97ebab0de851716d33d5ddbafa4a0a.png" width="512" height="381" class="img_ev3q"></p><p>Breaking the Enigma cipher involved identifying patterns in ciphertext to deduce the underlying encryption keys. Modern neural networks, particularly in deep learning, excel at recognising patterns in complex datasets. Image and speech recognition, genomics, and medical imaging are all fields where we use trend detection nowadays. </p><p>Alan Turing’s Bombe is considered to be an early example of a deterministic (predictable) finite automaton (DFA), which is a theoretical model of computation that processes input step by step (ciphertext), transitioning between predefined states (in his case, rotor positions) according to a set of rules.  Bombe's operation highlighted the essence of algorithmic problem-solving and showed the potential of automation, by minimising human error and speeding up repetitive tasks, both now the core principles of AI.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-turing-test">The Turing Test<a href="#the-turing-test" class="hash-link" aria-label="Direct link to The Turing Test" title="Direct link to The Turing Test">​</a></h3><p>The lessons learnt from Enigma’s cryptanalysis then got Turing thinking about intelligence. His well-known 1950 paper, “Computing Machinery and Intelligence,” posed the provocative question, “Can machines think?”. He proposed the Turing Test, a standard to determine whether the machine intelligence can be distinguished from the human one. The original Turing Test is set out this way:</p><ul><li>Three participants, human evaluator, human respondent and a machine.</li><li>After some dialogue, the evaluator will have to decide whether they are interacting with a machine or a human. </li><li>If the machine succeeds in deceiving the evaluator, it has passed the Turing Test. </li></ul><p>The principles of the Turing Test have sparked divergent evaluations over the past decades. Critics today argue that machines might pass the Turing Test by simply mimicking human-like responses without needing to demonstrate any thought or consciousness. So, they say, passing the Turing Test does not mean that these machines have human-like intelligence; rather, it is overly focused on language, and cognition cannot be fully captured by text-based communication. There now exist numerous alternatives such as Coffee Test, Visual Turing Test, The Lovelace Test, The Theory of Mind test, that take many other modalities into account such as visual perception, decision-making or even emotional understanding.</p><p>Alan Turing and the work of cryptologists during WWII have directed and pioneered the development of modern computing and created out many major ideas, still inspiring works in the Artificial Intelligence field today. However, we are still on a journey to realise how machines evolve. Even current AI models like ChatGPT-4 and Google Bard haven't yet advanced to a point where they can consistently pass the Turing test. In fact, nothing in AI today is even close to meeting the true intent of the Turing Test. The pursuit of creating machines that truly emulate human-like intelligence remains an ongoing challenge.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References">​</a></h3><p>Ferris, J. (2015). Intelligence. The Cambridge History of the Second World War, pp.637–663. doi:<a href="https://doi.org/10.1017/cho9781139855969.027" target="_blank" rel="noopener noreferrer">https://doi.org/10.1017/cho9781139855969.027</a>.</p><p>Dolan, J. (2023). Is the Turing Test Outdated? 5 Turing Test Alternatives. <!-- -->[online]<!-- --> MUO. Available at: <a href="https://www.makeuseof.com/is-turing-test-outdated-turing-test-alternatives/" target="_blank" rel="noopener noreferrer">https://www.makeuseof.com/is-turing-test-outdated-turing-test-alternatives/</a>.</p>]]></content:encoded>
            <category>history</category>
            <category>ww2</category>
            <category>turing</category>
            <category>turing test</category>
            <category>chatbots</category>
        </item>
        <item>
            <title><![CDATA[Playing Technocrat's Advocate]]></title>
            <link>https://uclaisociety.co.uk/blog/algorithms-in-government</link>
            <guid>https://uclaisociety.co.uk/blog/algorithms-in-government</guid>
            <pubDate>Fri, 13 Dec 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Algorithms everywhere are the way forward, whether we like it or not, and it's time to accept it.]]></description>
            <content:encoded><![CDATA[<p><em>Algorithms everywhere are the way forward, whether we like it or not, and it's time to accept it.</em></p><p>I wouldn’t disagree with anyone who thinks the algorithms that influence what we see, what we learn, and how we interact with technology and the internet are scary.</p><p>Ask how they work? These shapeless entities are sometimes indescribable, even by the engineers who initially wrote them. Then there’s the issues of algorithms that just don’t work for any number of reasons – the harmful human biases behind erroneous outputs, overfitted algorithms crumbling outside the nursery of a training set, or on the other hand, algorithms that are pushed into service too early.</p><p>Consider then the possibility that these algorithms don’t just exist on your Instagram feed or the Amazon home page. Consider the possibility that these systems are making real decisions on human lives. Consider a reality where they choose <a href="https://assets.publishing.service.gov.uk/media/5f3e125cd3bf7f1b13f65134/6674_Requirements_for_the_calculation_of_results_in_summer_2020_inc._Annex_G.pdf" target="_blank" rel="noopener noreferrer">who passes an exam and who fails</a>; <a href="https://www.ft.com/content/0206dd56-87b0-11e9-a028-86cea8523dc2" target="_blank" rel="noopener noreferrer">who stays and who is deported</a>; <a href="https://homeofficemedia.blog.gov.uk/2023/10/29/police-use-of-facial-recognition-factsheet/" target="_blank" rel="noopener noreferrer">who is a criminal and who walks free</a>.</p><p>That reality is here already. So why not reform it while we still can? We’re still quite far away from the days of sentient robotic overlords. Before we get there though, it would be a good idea to build responsible AIs, rather than reckless, anthropomorphic ones.</p><p>Take the case of the Ministry of Justice (MoJ) reaching out to the big data consultants Palantir about <a href="https://www.theguardian.com/technology/2024/nov/16/tech-firm-palantir-spoke-with-moj-about-calculating-prisoners-reoffending-risks" target="_blank" rel="noopener noreferrer">using their tech to calculate prisoners’ reoffending risks</a>. Whatever you think of Palantir, or the MoJ for that matter, this marks an auspiciously tech-savvy move from the Civil Service. The British prison system veered dangerously close to a crisis in the summer, and had to take emergency measures, such as <a href="https://www.gov.uk/government/news/process-activated-to-manage-prisoner-movements" target="_blank" rel="noopener noreferrer">early releases of certain eligible prisoners</a>, to ensure it didn’t reach breaking point. This was the result of over a decades’ worth of chronic negligence, and it’s only expected to buy the government another few months without a new strategy.</p><p>Overcrowding has been an issue for a while – England and Wales have the <a href="https://prisonreformtrust.org.uk/wp-content/uploads/2024/02/Winter-2024-factfile.pdf" target="_blank" rel="noopener noreferrer">highest imprisonment rate in Western Europe</a>. Also, prisoners here have started spending longer in prison, with a convict serving <a href="https://www.statista.com/statistics/1100628/prison-sentence-length-in-england-and-wales-over-time/" target="_blank" rel="noopener noreferrer">an average of 20.9 months in 2023</a>, up from 15.5 in 2013. Without too much mental maths, you can start to see where the problems pile up. Throw in the fact that two in five adults are reconvicted in less than a year after release, and now retaining this strained system seems almost untenable.</p><p>We shouldn’t continue to allow humans to fail to deliver, when we can take this opportunity to build a completely new and improved system. It’s the best time ever to invest time and resources into the effervescent world of AI. The UK government have the chance to go all-in on a project that, pending success, will have tangible benefits for thousands of individuals disadvantaged by a flawed system.</p><p>I think reform can begin with what was originally discussed – algorithms that analyse and evaluate prisoners’ reoffending risks but to support human employees with their decision making, instead of full automation. This should reduce the amount of returning convicts for two reasons. </p><p>One, that if we produce an improved success rate, i.e. less convicts returning to prison, the problem of overcrowding shrinks immediately. Two, it also allows prisons to identify those who may need more time to readjust to normal life and offer support. Of course, the prison system isn’t currently built for rehabilitation, but that’s another conversation!
We could even take it one step further and use it to identify who would benefit more from alternative sentencing. Prison sentences shorter than 12 months are less effective at preventing reoffending than community orders, according to a 2024 Prison Reform Trust study. Granted, discretion is needed (!) but this is just one example from the breadth of potential created by AI.</p><p>However, we must ensure the same biases pervasive in other government algorithms are eroded first. Responsible AI principles must be used in this system’s building – stakeholders should understand how it works without it being exploitable, and training sets should be curated to ensure fair representation across class, background, and representation. These systems should also be able to learn from the human decisions made alongside its use, to further tune its decision-making without falling into bias.</p><p>The success of technology in failing institutions is the seed for a future powered by it. It’s the seed for a future without decisions made by humans. However, a future without humans is a future without accountability. Let’s hope this future doesn’t arrive too early.</p>]]></content:encoded>
            <category>big data</category>
            <category>government</category>
            <category>policy</category>
        </item>
        <item>
            <title><![CDATA[AI and the Protein Revolution: Reshaping Our Future]]></title>
            <link>https://uclaisociety.co.uk/blog/nobel-prizes-2024</link>
            <guid>https://uclaisociety.co.uk/blog/nobel-prizes-2024</guid>
            <pubDate>Sun, 20 Oct 2024 00:00:00 GMT</pubDate>
            <description><![CDATA["These breakthroughs introduce us to a golden era of science and completely rewrite our future."]]></description>
            <content:encoded><![CDATA[<p><em>"These breakthroughs introduce us to a golden era of science and completely rewrite our future."</em></p><p><strong>Demis Hassabis</strong>, CEO of DeepMind, junior chess prodigy, former game developer and, of course, UCL alumnus, made headlines last week by joining the ranks of Nobel Laureates in Chemistry. He and his colleague, <strong>John M. Jumper</strong>, senior science researcher at DeepMind, achieved a game-changing breakthrough by pioneering new methods for predicting protein structures with Artificial Intelligence, and were awarded the half the Nobel Prize for their efforts.​</p><p>Along with that, <strong>David Baker</strong>, professor of biochemistry and Director of the Institute for Protein Design at the University of Washington has been awarded the other half of the 2024 Nobel Prize in Chemistry for computational protein design.</p><p>These breakthroughs introduce us to a golden era of science and completely rewrite our future. And here's why we must talk about it. </p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="david-baker">David Baker<a href="#david-baker" class="hash-link" aria-label="Direct link to David Baker" title="Direct link to David Baker">​</a></h3><p><em>“In nature, proteins are the miniature machines that carry out all the important jobs: we can think, we can move, we can digest food, plants can capture energy from the sunlight and everything that happens in the living organism is due to proteins. We can use proteins to solve problems that evolution did not manage to solve.”</em> - David Baker.</p><p>Each protein chain folds into its own characteristic shape and the folding process is very precise. The shape of a folded protein chain is what defines its biological functions. However, there are so many different shapes a protein can adopt, which made the protein problem so difficult and rendered it unsolved for over 50 years. Up until now. </p><p>The gigantic increase in computing power since the problem’s discovery now enables us to design tens of thousands of new proteins with new shapes and new functions. There are now over 10<sup>130</sup> different designs we can explore using computation, enormously larger than the total number of proteins that have existed since life on earth began. After creation, we can  extract the proteins, and then determine their functions and whether they are safe. </p><p>Today we face challenges such as serious ecological threats as well as new diseases evolving, and we do not have millions of years to wait for the discovery of the right proteins. But using computational design tools, we can now build these completely new multi-purpose proteins. </p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="john-m-jumper-and-demis-hassabis">John M. Jumper and Demis Hassabis<a href="#john-m-jumper-and-demis-hassabis" class="hash-link" aria-label="Direct link to John M. Jumper and Demis Hassabis" title="Direct link to John M. Jumper and Demis Hassabis">​</a></h3><p>The AI system <em>AlphaFold2</em> by DeepMind is the first non-experimental method that can predict the complex structure of any known protein in nature, also solving the "50-year grand challenge", in the words of Hassabis himself. This system can predict the way a protein folds based on the amino acid sequence it consists of, which enables us to create proteins that can perform very specific functions and help us drive humanity's development. </p><p>Until very recently it could take research biologists a year to get a single answer about a 3D shape of a protein fold; now we have a machine learning algorithm that can do the same in 5-10 minutes. </p><p><img loading="lazy" alt="Alt text" src="/assets/images/nobel-prize-1-ade817e74f40c2dc5d4d94b423fbb32a.png" width="512" height="201" class="img_ev3q"></p><p>The program consists of three stages: database search and preprocessing, <em>EvoFormer</em>, and structure model. </p><p><strong>Database search and preprocessing.</strong> A sequence of amino acids is entered, and <em>AlphaFold</em> compares it to records from several databases to extract similar sequences from other organisms. It also creates a pair representation of this input sequence, showing pairs of amino acid residues that are close together in 3D space within the target protein. Residue is the part of an amino acid that remains after it forms a peptide chain with other amino acids, and water is removed.</p><p><strong><em>EvoFormer</em></strong> is a unique <em>AlphaFold</em> neural network that looks for relationships in residue pairs of the input sequence. It also evaluates the relationship within any two residues, which can be thought of as nodes in NNs. These calculations are carried out 48 times before forming a refined model of residue pair representations. </p><p>Finally, <strong>the Structure Model</strong> is another neural network that takes the previously refined model and performs rotation and translation on it to create a prediction of what its 3D protein structure looks like.</p><p>These newly developed proteins can fight cancer, break down plastic waste, and develop vaccines for respiratory diseases among many other uses. This intersection of biology and AI in 2024 can help us uncover the secrets of life, fight diseases, and even address the overwhelming climate challenges of today and the future.</p>]]></content:encoded>
            <category>nobel prize</category>
            <category>chemistry</category>
        </item>
        <item>
            <title><![CDATA[Welcome (or Welcome Back)]]></title>
            <link>https://uclaisociety.co.uk/blog/reintroductions</link>
            <guid>https://uclaisociety.co.uk/blog/reintroductions</guid>
            <pubDate>Tue, 01 Oct 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Welcome (or welcome back) to UCL Artificial Intelligence Society’s blog!]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="welcome-or-welcome-back-to-ucl-artificial-intelligence-societys-blog">Welcome (or welcome back) to UCL Artificial Intelligence Society’s blog!<a href="#welcome-or-welcome-back-to-ucl-artificial-intelligence-societys-blog" class="hash-link" aria-label="Direct link to Welcome (or welcome back) to UCL Artificial Intelligence Society’s blog!" title="Direct link to Welcome (or welcome back) to UCL Artificial Intelligence Society’s blog!">​</a></h2><p>I’m Anthony, the new Head of Content, and I just can’t wait for everything we’ve got planned for UCL AI Society this year. </p><p>The year ahead is looking exciting – there’s a lot going on. We have the return of our incredible initiatives. We’re getting a new season of Reinforcement Talking, the UCL AI Society podcast <strong>(episode coming out VERY soon)</strong>. And of course, our brilliant <em>blog</em> is back for another year. In this mini-update, I'm going to walk you through what's happening in the coming days and weeks. </p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="whats-on">What's on?<a href="#whats-on" class="hash-link" aria-label="Direct link to What's on?" title="Direct link to What's on?">​</a></h2><p><strong>Tutorials</strong> are back, where you can learn how to code a vast range of machine learning techniques, completely free for our members. It's every Wednesday, open to all ranges of abilities, so get it onto your calendars.</p><p>Then we have <strong>Nexus Labs</strong>, where you can put these skills to work on a research project, exploring one of neuroscience, robotics, GenAI, practical AI, or responsible AI, culminating in an epic symposium where you can present your findings.</p><p>For the visionaries and entrepreneurs amongst our membership (yes, get yours now if you haven’t), you can apply to <strong>AI Foundry</strong>, which provides you with a series of workshops, mentoring opportunities, and chances to pitch your brainchildren to keen investors, and industry experts. </p><p>Finally, <strong>Journal Clubs</strong> invite some of the world’s greatest minds in AI for live and exclusive talks about their research – we’ve hosted individuals from top institutions across the globe talking about everything between machine learning theory and its applications.</p><p>That’s not just it though. We’ve got hackathons coming up, some big events, career panels, and more… but stay updated through this blog and our members’ newsletter to hear about these as soon as they’re confirmed.</p>]]></content:encoded>
            <category>welcome</category>
            <category>introductions</category>
            <category>events</category>
            <category>miniblog</category>
        </item>
        <item>
            <title><![CDATA[Is AI an existential risk?]]></title>
            <link>https://uclaisociety.co.uk/blog/ai-safety-debate</link>
            <guid>https://uclaisociety.co.uk/blog/ai-safety-debate</guid>
            <pubDate>Sun, 17 Mar 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[AI Safety Debate]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="ai-safety-debate">AI Safety Debate<a href="#ai-safety-debate" class="hash-link" aria-label="Direct link to AI Safety Debate" title="Direct link to AI Safety Debate">​</a></h2><p>It was a real privilege to host, alongside two of the best societies at UCL – AI Society, and UCL Effective Altruism – our AI Safety Debate, on the topic of, “Is AI an existential risk?”</p><p>🎬 A full recording can be found <a href="https://www.youtube.com/watch?v=mcozzJbLbZI" target="_blank" rel="noopener noreferrer">here</a>, if you want to watch the whole thing.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="why-talk-about-ai-safety">Why talk about AI safety?<a href="#why-talk-about-ai-safety" class="hash-link" aria-label="Direct link to Why talk about AI safety?" title="Direct link to Why talk about AI safety?">​</a></h3><p>I believed it was important to host this debate because I think this question is, potentially, highly important, but also, one which I have deep uncertainties about. Many AI experts like Geoffrey Hinton think that AI should be considered just as risky as pandemics or nuclear war, and that we need to slow down, or pause its development. Others, like Melanie Mitchell, believe that the risks are “almost vanishingly small”. The stakes of the question for humanity warrant a serious (and long, in my opinion) conversation about the respective arguments’ merits.</p><p>After this prelude, my wonderful colleagues Ivana and Maja introduced the speakers. We were lucky enough to have <a href="https://www.linkedin.com/in/reuben-adams-10031b180/?originalSubdomain=uk" target="_blank" rel="noopener noreferrer">Reuben Adams</a> and <a href="https://www.cs.rhul.ac.uk/~chrisw/" target="_blank" rel="noopener noreferrer">Chris Watkins</a> arguing for the “doomer” side (as we referred to it, in the WhatsApp group chat). Reuben is a UCL AI PhD student, and host of the wonderful <a href="https://www.ucl.ac.uk/ai-centre/steering-ai-podcast" target="_blank" rel="noopener noreferrer">‘Steering AI’ Podcast</a>. Chris is a professor at Royal Holloway, and a prominent thinker in the ‘Reinforcement Learning’ field. For the ‘risk-skeptical side’ (the ‘anti-doomer’ side??), was <a href="https://www.linkedin.com/in/jack-stilgoe-2a6187a/?originalSubdomain=uk" target="_blank" rel="noopener noreferrer">Jack Stilgoe</a> and <a href="https://www.linkedin.com/in/kenneth-cukier-9ab56335/?originalSubdomain=uk" target="_blank" rel="noopener noreferrer">Kenn Cukier</a>. Jack is a UCL professor, on “home-turf” as he said, lecturing in Science and Technology Studies (STS), and works closely with UK Research and Innovation on the “Responsible AI Program”. Kenn is a Deputy Executive Editor at The Economist magazine, and hosts the weekly tech podcast, “Babbage” . <a href="https://uk.linkedin.com/in/tomough" target="_blank" rel="noopener noreferrer">Tom Ough</a>, a freelance journalist, who’s written various pieces about existential risk, including in Prospect Magazine, was moderating. Ivana encouraged our audience to consider how the lack of demographic diversity on the panel could systematically bias the conversation, which (as you’ll read) came up in discussions.</p><p>At face value, the 4 speakers seemed to argue distinctly opposing points of view. I will briefly give my best effort at summarizing their views, in the order in which they spoke. After, I look to set out promising areas of agreement amongst all the panelists.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-debate">The debate<a href="#the-debate" class="hash-link" aria-label="Direct link to The debate" title="Direct link to The debate">​</a></h3><p>Reuben opened the debate. He argued that the new paradigm of deep-learning presents a distinctly new category of AI risk: we are building ever-more intelligent ‘black-boxes’, with novel capabilities we cannot predict. Once there is a “second species of intelligence” that rivals our own, we are completely ignorant about what will follow. Our current tools for controlling AI systems, like ‘RLHF’, are woefully inadequate even at present, and won’t ‘scale up’ with increasing AI progress. What follows from all this? “I don’t understand how you can confidently say that this doesn’t end badly.”</p><p>After Reuben, came Jack. He eased his way into his argument with several cool anecdotes. (From Reuben’s speech, the day after Earnest Rutherford denied the feasibility of nuclear energy, in September 1933, Leo Szilard conceived of the nuclear chain reaction. Jack said that the concept came to Szilard by Russell Square Station. Go there if you want to conceive of the next big thing). Anyway. Back to the seriousness. Rogue AI scenarios are implausible and belong in science fiction. Instead, “the idea of existential risk from AI is a form of displacement activity”, from other more pressing concerns, like the disempowerment of workers or marginalization of minorities. These are the risks that deserve regulators’ attention. A more interesting question, for Jack, is why people are drawn towards believing these risks: perhaps peoples’ positionality, or for some technologists their self-interest. AI is a tool like any other, in that it’s “all about power”, so “we shouldn’t be worrying about what robots will do to humanity, instead we should worry about what some people will do to other people”.</p><p>After Jack, there was Chris. From his perspective, the algorithmic breakthroughs that enabled ChatGPT are pedestrian. His MSc students are already implementing the “transformer” architecture for their coursework, the major breakthrough behind large language models like ChatGPT. Given that tens of thousands of people and 11 figure sums are being directed towards AI, we have no reason to believe that further breakthroughs won’t occur. Instead, we should expect a future of open-ended cognitive advancement. This unknowable future is “behind a veil”. While we aren’t necessarily destined for doom, there are plausible “side-roads” that lead towards it, in particular AI-enabled authoritarian regimes.</p><p>Finally, it was Kenn’s turn. “This is bleak!”, he started with. Whilst the risks from AI are serious, they won’t scale to an ‘existential catastrophe’. Existing alignment techniques like RLHF put humans in the loop, and will obstruct any ‘intelligence explosion’. Humans are unlikely to cede control of political power or nuclear missile systems to AI. Among different possible futures, we can design “love” into AI. In contrast, misuse risks do seem concerning. Kenn was anxious when news broke in 2022 that AI had developed 40,000 toxic chemicals in 6 hours. However, there is nuance here. The threat model of ‘misuse risks’ from bad actors already exists today. Lethal Autonomous Weapons may make warfare less brutal. So, let’s not be defeatist, and instead focus on “existential solutions”.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="disagreements">(Dis)agreements!<a href="#disagreements" class="hash-link" aria-label="Direct link to (Dis)agreements!" title="Direct link to (Dis)agreements!">​</a></h3><p>A key disagreement for the participants seemed to be: Reuben and Chris seemed to acknowledge that exact pathways to catastrophe are unknowable – and would be analogous to bonobos trying to predict how they would be outcompeted by humans. Kenn, and particularly Jack, emphasized this point, and suggested that the ‘rogue AI story’ parallels science fiction. Reuben/Chris seem to bite the bullet.</p><p>However, amongst these disagreements, there were several areas of agreement, which questions from our moderator, Tom, helped to elucidate:</p><ul><li>Proactive oversight/regulation of AI systems today is necessary to guard against present-day harms, like misinformation.</li><li>Careful evaluations of AI models is an area of potential common ground between those concerned about ‘near-term’ and ‘long-term risks’ from AI.</li><li>AI represents a new (potentially transformative) era for humanity</li><li>Predicting exactly how the future will unfold is nigh on impossible; speculation about how exactly AI harms might scale to catastrophe or even extinction is very difficult to conceive precisely.</li><li>AI is likely to be a “force-multiplier” and may enable bad actors to do worse things</li></ul><p>On these points, and others, I think the speakers realized that their worldviews were closer than they might have expected.</p><p>I am very grateful to Ivana, Maja, Asmita for helping with the organizing of the event, and to Andrzej and Yadong for helping with the filming.</p>]]></content:encoded>
            <category>ai safety</category>
            <category>debate</category>
        </item>
        <item>
            <title><![CDATA[Welcome to the UCL AI Society]]></title>
            <link>https://uclaisociety.co.uk/blog/welcome</link>
            <guid>https://uclaisociety.co.uk/blog/welcome</guid>
            <pubDate>Wed, 30 Aug 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[Hello and welcome to the very first UCL AI Society blogpost of the year!]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hello-and-welcome-to-the-very-first-ucl-ai-society-blogpost-of-the-year">Hello and welcome to the very first UCL AI Society blogpost of the year!<a href="#hello-and-welcome-to-the-very-first-ucl-ai-society-blogpost-of-the-year" class="hash-link" aria-label="Direct link to Hello and welcome to the very first UCL AI Society blogpost of the year!" title="Direct link to Hello and welcome to the very first UCL AI Society blogpost of the year!">​</a></h2><p>My name is Jessica and I’m so excited to be your Creative Director this year 😄, You’ll be hearing from me every week about <strong>the AI buzz and news on the society</strong>, and <strong>any upcoming events</strong> you should bookmark in your calendar, so be sure to keep your eyes peeled on the society blog to stay updated 📚️.</p><p>With the introductions out of the way, today’s blog post is for all our new members and getting you up-to-date on what this is all about. First of all, massive congratulations on getting into UCL! That is no small feat, and we’re so glad you were able to join us in not-so-sunny London 🌧️ (it gets better in February, trust). Secondly, congratulations on having excellent taste in societies, and frankly, joining the best one out there. We promise you’re going to have a good time.</p><p>Since our inception, the UCL AI Society has grown massively, and we’re proud to say that we are one of the most prolific student societies at UCL. We’d like to think it’s because we have something for everyone, even for those who aren’t compsci students or know how to code! Artificial intelligence is something that will affect everyone in the years to come, regardless of who you are, and as a result, we believe our society should be accessible and relevant to all pathways and disciplines. We hope the AI society can be your place to explore your interests, build long-lasting relationships and make memories for life. Some of the social events you can get involved in are our iconic Thursday Pizza Socials 🍕 (free pizza for all!), speaker events with world-renowned researchers 🧑‍🏫, tutorials 💻️, cross-university networking events 🧑‍🤝‍🧑, and more.</p><p>We also have programs running on a larger scale for those of you who want to improve your own skills, dip into research or begin a start-up. For research, we have the Nexus Labs project 🧑‍💻, which is an interdisciplinary initiative for students to engage in one of five academic pillars: Neuroscience, NLP, Finance, Machine Vision and Responsible AI ✏️. Within each pillar, teams will have a specialist on board to explore a question with the aim of publishing a research paper at the end of the project.</p><p>For those of you wanting to explore the world of entrepreneurship, we have the UCL AI Foundry 📈, our incubator for budding AI businesses. Upon joining Foundry, you’ll be given guidance, support and advice throughout the project from assigned mentors. At the end, you’ll be given an opportunity to pitch your start-up to a panel of investors who can help your business take off.</p><p>And finally, our biggest event of the year: ClimateHack.AI 🌎️, our society hackathon which brings together 25 leading universities to solve some of our climate’s most pressing problems.</p><p>This year, ClimateHack.AI is helping to solve the issue of solar nowcasting ☀️, essentially helping us optimise solar panels as solar power is highly variable considering weather conditions. By building better solar photovoltaic nowcasting, we’re able to help derisk the deployment of solar power and encourage its use in energy grids around the world. In the UK alone, this could help us reduce 100,000 tonnes of carbon emissions. Around the world, there would be a reduction of 50 to 100 million tonnes of carbon.</p><p>For ClimateHack.AI 2022, we focused on satellite imagery nowcasting 🛰️ and managed to build a model 3.5x more accurate than the one being used by the National Grid Electricity System Operator (NG-ESO). As a result, we know the impact ClimateHack.AI has, and we’ve seen the good it can do. For ClimateHack.AI 2023, we encourage you to participate if this is something that catches your eye! We can’t make a tangible impact without your help, and the hackathon has been some of our previous members’ favourite part of the society, so we guarantee it’ll be a good time. You’ll be able to meet like-minded individuals, expand your network and career opportunities, and have a shot at our prize pool with a grand first prize of £15,000 💰️!</p><p>Ultimately, as you can probably see, UCL AI Society is packed full of different events happening every week, and as your committee, we’re dedicated to making sure this society provides everything possible to help you thrive both personally and professionally 🫡. Regardless, we hope we’ll see you in some of these events once the school year starts up, and as always, feel free to reach out with any questions.</p><p>See you next week! 👋</p><p>Jessica</p>]]></content:encoded>
            <category>welcome</category>
        </item>
    </channel>
</rss>