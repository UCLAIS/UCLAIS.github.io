<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">One post tagged with &quot;debate&quot; | UCL Artificial Intelligence Society</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://uclaisociety.co.uk/blog/tags/debate/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="One post tagged with &quot;debate&quot; | UCL Artificial Intelligence Society"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/img/logo.png"><link data-rh="true" rel="canonical" href="https://uclaisociety.co.uk/blog/tags/debate/"><link data-rh="true" rel="alternate" href="https://uclaisociety.co.uk/blog/tags/debate/" hreflang="en"><link data-rh="true" rel="alternate" href="https://uclaisociety.co.uk/blog/tags/debate/" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="UCL Artificial Intelligence Society RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="UCL Artificial Intelligence Society Atom Feed">




<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Bebas+Neue&amp;display=swap">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.2d0488b2.css">
<link rel="preload" href="/assets/js/runtime~main.4ec52ad6.js" as="script">
<link rel="preload" href="/assets/js/main.3102a2b2.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbar--dark"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo_light.svg" alt="UCL AI Society Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo_light.svg" alt="UCL AI Society Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">UCL AI Society</b></a><a class="navbar__item navbar__link" href="/about-us/">About Us</a><a class="navbar__item navbar__link" href="/our-initiatives/">Our Initiatives</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog/">Blog</a><a class="navbar__item navbar__link" href="/our-initiatives/holistic-ai-hackathon/">Holistic AI Hackathon</a></div><div class="navbar__items navbar__items--right"><a href="https://dashboard.mailerlite.com/forms/364819/102382926138704937/share" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Newsletter ğŸ—ï¸<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://doxaai.com/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">DOXA<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://climatehack.ai/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">ClimateHack.AI<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/nobel-prizes-2024/">AI and the Protein Revolution: Reshaping Our Future</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/reintroductions/">Welcome (or Welcome Back)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/ai-safety-debate/">Is AI an existential risk?</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/welcome/">Welcome to the UCL AI Society</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>One post tagged with &quot;debate&quot;</h1><a href="/blog/tags/">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="AI Safety Debate"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/ai-safety-debate/">Is AI an existential risk?</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-03-17T00:00:00.000Z" itemprop="datePublished">March 17, 2024</time> Â· <!-- -->6 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><img class="avatar__photo" src="/img/committee/charlie_harrison.jpg" alt="Charlie Harrison" itemprop="image"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><span itemprop="name">Charlie Harrison</span></div><small class="avatar__subtitle" itemprop="description">Head of Content</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><h2 class="anchor anchorWithStickyNavbar_LWe7" id="ai-safety-debate">AI Safety Debate<a href="#ai-safety-debate" class="hash-link" aria-label="Direct link to AI Safety Debate" title="Direct link to AI Safety Debate">â€‹</a></h2><p>It was a real privilege to host, alongside two of the best societies at UCL â€“ AI Society, and UCL Effective Altruism â€“ our AI Safety Debate, on the topic of, â€œIs AI an existential risk?â€</p><p>ğŸ¬ A full recording can be found <a href="https://www.youtube.com/watch?v=mcozzJbLbZI" target="_blank" rel="noopener noreferrer">here</a>, if you want to watch the whole thing.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="why-talk-about-ai-safety">Why talk about AI safety?<a href="#why-talk-about-ai-safety" class="hash-link" aria-label="Direct link to Why talk about AI safety?" title="Direct link to Why talk about AI safety?">â€‹</a></h3><p>I believed it was important to host this debate because I think this question is, potentially, highly important, but also, one which I have deep uncertainties about. Many AI experts like Geoffrey Hinton think that AI should be considered just as risky as pandemics or nuclear war, and that we need to slow down, or pause its development. Others, like Melanie Mitchell, believe that the risks are â€œalmost vanishingly smallâ€. The stakes of the question for humanity warrant a serious (and long, in my opinion) conversation about the respective argumentsâ€™ merits.</p><p>After this prelude, my wonderful colleagues Ivana and Maja introduced the speakers. We were lucky enough to have <a href="https://www.linkedin.com/in/reuben-adams-10031b180/?originalSubdomain=uk" target="_blank" rel="noopener noreferrer">Reuben Adams</a> and <a href="https://www.cs.rhul.ac.uk/~chrisw/" target="_blank" rel="noopener noreferrer">Chris Watkins</a> arguing for the â€œdoomerâ€ side (as we referred to it, in the WhatsApp group chat). Reuben is a UCL AI PhD student, and host of the wonderful <a href="https://www.ucl.ac.uk/ai-centre/steering-ai-podcast" target="_blank" rel="noopener noreferrer">â€˜Steering AIâ€™ Podcast</a>. Chris is a professor at Royal Holloway, and a prominent thinker in the â€˜Reinforcement Learningâ€™ field. For the â€˜risk-skeptical sideâ€™ (the â€˜anti-doomerâ€™ side??), was <a href="https://www.linkedin.com/in/jack-stilgoe-2a6187a/?originalSubdomain=uk" target="_blank" rel="noopener noreferrer">Jack Stilgoe</a> and <a href="https://www.linkedin.com/in/kenneth-cukier-9ab56335/?originalSubdomain=uk" target="_blank" rel="noopener noreferrer">Kenn Cukier</a>. Jack is a UCL professor, on â€œhome-turfâ€ as he said, lecturing in Science and Technology Studies (STS), and works closely with UK Research and Innovation on the â€œResponsible AI Programâ€. Kenn is a Deputy Executive Editor at The Economist magazine, and hosts the weekly tech podcast, â€œBabbageâ€ . <a href="https://uk.linkedin.com/in/tomough" target="_blank" rel="noopener noreferrer">Tom Ough</a>, a freelance journalist, whoâ€™s written various pieces about existential risk, including in Prospect Magazine, was moderating. Ivana encouraged our audience to consider how the lack of demographic diversity on the panel could systematically bias the conversation, which (as youâ€™ll read) came up in discussions.</p><p>At face value, the 4 speakers seemed to argue distinctly opposing points of view. I will briefly give my best effort at summarizing their views, in the order in which they spoke. After, I look to set out promising areas of agreement amongst all the panelists.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-debate">The debate<a href="#the-debate" class="hash-link" aria-label="Direct link to The debate" title="Direct link to The debate">â€‹</a></h3><p>Reuben opened the debate. He argued that the new paradigm of deep-learning presents a distinctly new category of AI risk: we are building ever-more intelligent â€˜black-boxesâ€™, with novel capabilities we cannot predict. Once there is a â€œsecond species of intelligenceâ€ that rivals our own, we are completely ignorant about what will follow. Our current tools for controlling AI systems, like â€˜RLHFâ€™, are woefully inadequate even at present, and wonâ€™t â€˜scale upâ€™ with increasing AI progress. What follows from all this? â€œI donâ€™t understand how you can confidently say that this doesnâ€™t end badly.â€</p><p>After Reuben, came Jack. He eased his way into his argument with several cool anecdotes. (From Reubenâ€™s speech, the day after Earnest Rutherford denied the feasibility of nuclear energy, in September 1933, Leo Szilard conceived of the nuclear chain reaction. Jack said that the concept came to Szilard by Russell Square Station. Go there if you want to conceive of the next big thing). Anyway. Back to the seriousness. Rogue AI scenarios are implausible and belong in science fiction. Instead, â€œthe idea of existential risk from AI is a form of displacement activityâ€, from other more pressing concerns, like the disempowerment of workers or marginalization of minorities. These are the risks that deserve regulatorsâ€™ attention. A more interesting question, for Jack, is why people are drawn towards believing these risks: perhaps peoplesâ€™ positionality, or for some technologists their self-interest. AI is a tool like any other, in that itâ€™s â€œall about powerâ€, so â€œwe shouldnâ€™t be worrying about what robots will do to humanity, instead we should worry about what some people will do to other peopleâ€.</p><p>After Jack, there was Chris. From his perspective, the algorithmic breakthroughs that enabled ChatGPT are pedestrian. His MSc students are already implementing the â€œtransformerâ€ architecture for their coursework, the major breakthrough behind large language models like ChatGPT. Given that tens of thousands of people and 11 figure sums are being directed towards AI, we have no reason to believe that further breakthroughs wonâ€™t occur. Instead, we should expect a future of open-ended cognitive advancement. This unknowable future is â€œbehind a veilâ€. While we arenâ€™t necessarily destined for doom, there are plausible â€œside-roadsâ€ that lead towards it, in particular AI-enabled authoritarian regimes.</p><p>Finally, it was Kennâ€™s turn. â€œThis is bleak!â€, he started with. Whilst the risks from AI are serious, they wonâ€™t scale to an â€˜existential catastropheâ€™. Existing alignment techniques like RLHF put humans in the loop, and will obstruct any â€˜intelligence explosionâ€™. Humans are unlikely to cede control of political power or nuclear missile systems to AI. Among different possible futures, we can design â€œloveâ€ into AI. In contrast, misuse risks do seem concerning. Kenn was anxious when news broke in 2022 that AI had developed 40,000 toxic chemicals in 6 hours. However, there is nuance here. The threat model of â€˜misuse risksâ€™ from bad actors already exists today. Lethal Autonomous Weapons may make warfare less brutal. So, letâ€™s not be defeatist, and instead focus on â€œexistential solutionsâ€.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="disagreements">(Dis)agreements!<a href="#disagreements" class="hash-link" aria-label="Direct link to (Dis)agreements!" title="Direct link to (Dis)agreements!">â€‹</a></h3><p>A key disagreement for the participants seemed to be: Reuben and Chris seemed to acknowledge that exact pathways to catastrophe are unknowable â€“ and would be analogous to bonobos trying to predict how they would be outcompeted by humans. Kenn, and particularly Jack, emphasized this point, and suggested that the â€˜rogue AI storyâ€™ parallels science fiction. Reuben/Chris seem to bite the bullet.</p><p>However, amongst these disagreements, there were several areas of agreement, which questions from our moderator, Tom, helped to elucidate:</p><ul><li>Proactive oversight/regulation of AI systems today is necessary to guard against present-day harms, like misinformation.</li><li>Careful evaluations of AI models is an area of potential common ground between those concerned about â€˜near-termâ€™ and â€˜long-term risksâ€™ from AI.</li><li>AI represents a new (potentially transformative) era for humanity</li><li>Predicting exactly how the future will unfold is nigh on impossible; speculation about how exactly AI harms might scale to catastrophe or even extinction is very difficult to conceive precisely.</li><li>AI is likely to be a â€œforce-multiplierâ€ and may enable bad actors to do worse things</li></ul><p>On these points, and others, I think the speakers realized that their worldviews were closer than they might have expected.</p><p>I am very grateful to Ivana, Maja, Asmita for helping with the organizing of the event, and to Andrzej and Yadong for helping with the filming.</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/ai-safety/">ai safety</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/debate/">debate</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Our Initiatives</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/our-initiatives/tutorials/">Tutorial Series</a></li><li class="footer__item"><a class="footer__link-item" href="/our-initiatives/nexus-labs/">Nexus Labs</a></li><li class="footer__item"><a class="footer__link-item" href="/our-initiatives/ai-foundry/">AI Foundry</a></li><li class="footer__item"><a class="footer__link-item" href="/our-initiatives/journal-club/">Journal Club</a></li><li class="footer__item"><a class="footer__link-item" href="/our-initiatives/holistic-ai-hackathon/">Holistic AI x UCL AI Society Hackathon</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/KSUZuQx?ltclid=3f704b3b-9044-415a-a2d7-e41007214187" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.facebook.com/AISoc.ucl/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Facebook<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.instagram.com/uclaisociety/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Instagram<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/company/ucl-artificial-intelligence-society/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://dashboard.mailerlite.com/forms/364819/102382926138704937/share" target="_blank" rel="noopener noreferrer" class="footer__link-item">Subscribe to our Newsletter! ğŸ—ï¸</a></li><li class="footer__item"><a class="footer__link-item" href="/blog/">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://doxaai.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">DOXA<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://climatehack.ai/" target="_blank" rel="noopener noreferrer" class="footer__link-item">ClimateHack.AI<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2024 UCL Artificial Intelligence Society</div></div></div></footer></div>
<script src="/assets/js/runtime~main.4ec52ad6.js"></script>
<script src="/assets/js/main.3102a2b2.js"></script>
</body>
</html>