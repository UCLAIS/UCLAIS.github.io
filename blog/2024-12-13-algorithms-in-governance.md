---
slug: algorithms-in-government
title: Playing Technocrat's Advocate
authors: [anthony]
tags: [big data, government, policy, miniblog]
---
I wouldn’t disagree with anyone who thinks the algorithms that influence what we see, what we learn, and how we interact with technology and the internet are scary.

Ask how they work? These shapeless entities are sometimes indescribable, even by the engineers who initially wrote them. Then there’s the issues of algorithms that just don’t work for any number of reasons – the harmful human biases behind erroneous outputs, overfitted algorithms crumbling outside the nursery of a training set, or on the other hand, algorithms that are pushed into service too early.

Consider then the possibility that these algorithms don’t just exist on your Instagram feed or the Amazon home page. Consider the possibility that these systems are making real decisions on human lives. Consider a reality where they choose who passes an exam and who fails; who stays and who is deported; who is a criminal and who walks free.

That reality is here already. So why not reform it while we still can? We’re still quite far away from the days of sentient robotic overlords. Before we get there though, it would be a good idea to build responsible AIs, rather than reckless, anthropomorphic ones.

Take the case of the Ministry of Justice (MoJ) reaching out to the big data consultants Palantir about using their tech to calculate prisoners’ reoffending risks. Whatever you think of Palantir, or the MoJ for that matter, this marks an auspiciously tech-savvy move from the Civil Service. The British prison system veered dangerously close to a crisis in the summer, and had to take emergency measures, such as early releases of certain eligible prisoners, to ensure it didn’t reach breaking point. This was the result of over a decades’ worth of chronic negligence, and it’s only expected to buy the government another few months without a new strategy.

Overcrowding has been an issue for a while – England and Wales have the highest imprisonment rate in Western Europe. Also, our prisoners have started spending longer in prison, with a convict serving an average of 20.9 months in 2023, up from 15.5 in 2013. Without too much mental maths, you can start to see where the problems pile up. Throw in the fact that two in five adults are reconvicted in less than a year of release, and now retaining this strained system seems almost untenable.

We shouldn’t continue to allow humans to fail to deliver, when we can take this opportunity to build a completely new and improved system. It’s the best time ever to invest time and resources into the effervescent world of AI. The UK government have the chance to go all-in on a project that, pending success, will have tangible benefits for thousands of individuals disadvantaged by a flawed system.

I think reform can begin with what was originally discussed – algorithms that analyse and evaluate prisoners’ reoffending risks but to support human employees with their decision making, instead of full automation. This should reduce the amount of returning convicts for two reasons. 

One, that if we produce an improved success rate, i.e. less convicts returning to prison, the problem of overcrowding shrinks immediately. Two, it also allows prisons to identify those who may need more time to readjust to normal life and offer support. Of course, the prison system isn’t currently built for rehabilitation, but that’s another conversation!
We could even take it one step further and use it to identify who would benefit more from alternative sentencing. Prison sentences shorter than 12 months are less effective at preventing reoffending than community orders, according to a 2024 Prison Reform Trust study. Granted, discretion is needed (!) but this is just one example from the breadth of potential created by AI.

However, we must ensure the same biases pervasive in other government algorithms are eroded first. Responsible AI principles must be used in this system’s building – stakeholders should understand how it works without it being exploitable, and training sets should be curated to ensure fair representation across class, background, and representation. These systems should also be able to learn from the human decisions made alongside its use, to further tune its decision-making without falling into bias.

The success of technology in failing institutions is the seed for a future powered by it. It’s the seed for a future without decisions made by humans. However, a future without humans is a future without accountability. Let’s hope this future doesn’t arrive too early.

### References
1. Ofqual, “Requirements for the calculation of results in summer 2020: GCE (AS/A level), GCSE, Extended Project and Advanced Extension Award Qualifications,” Aug. 2020.   
2. H. Warrell, “Home Office under fire for using secretive visa algorithm,” Financial Times, Jun. 09, 2019. https://www.ft.com/content/0206dd56-87b0-11e9-a028-86cea8523dc2   
3. Home Office, “Police Use of Facial Recognition: Factsheet - Home Office in the Media,” homeofficemedia.blog.gov.uk, Oct. 29, 2023. https://homeofficemedia.blog.gov.uk/2023/10/29/police-use-of-facial-recognition-factsheet/   
4. B. Quinn, “Tech firm Palantir spoke with MoJ about calculating prisoners’ ‘reoffending risks,’” The Guardian, Nov. 16, 2024. https://www.theguardian.com/technology/2024/nov/16/tech-firm-palantir-spoke-with-moj-about-calculating-prisoners-reoffending-risks   
5. Ministry of Justice, HM Prison and Probation Service, and Lord Timpson OBE, “Process activated to manage prisoner movements,” gov.uk, Aug. 18, 2024. https://www.gov.uk/government/news/process-activated-to-manage-prisoner-movements   
6. Prison Reform Trust, “Bromley Briefings Prison Factfile,” Feb. 2024.   
7. D. Clark, “Average prison sentence length in England and Wales 2000-2019,” Statista, Jul. 18, 2024. https://www.statista.com/statistics/1100628/prison-sentence-length-in-england-and-wales-over-time/   
