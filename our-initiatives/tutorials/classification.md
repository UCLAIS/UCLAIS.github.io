---
sidebar_position: 5
---

# 3: Classification

**Date: 1st November 2023**

💡 **Classification** helps us to group data into predefined classes. **Logistic Regression** is a linear model used for binary classification, while **K-means** is an unsupervised clustering algorithm that categorizes data into clusters. **Support Vector Machines (SVM)** find an optimal hyperplane to separate data, and **Decision Trees** use a tree-like structure to make decisions based on feature attributes. Come to this session to explore and implement these four well-known classification methods! 💡

You can access our **demonstration notebook** here: 📘 [**Tutorial 3 Notebook**](https://github.com/UCLAIS/ml-tutorials-season-4/blob/main/week-3/p1_logistic_regression_exercise.ipynb)

The folder contains notebooks for Logistic Regression, SVMs, Decision Trees and K-Means. The solutions are available in the same folder.

You can access our **slides** here: 💻 [**Tutorial 3 Slides**](https://www.canva.com/design/DAFqI2cJlw0/Y-hfq3RUexRi18DBV0R0VA/edit?utm_content=DAFqI2cJlw0&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton)

The **recording** from this session is available here: 🎤 [**Tutorial 3 Recording**](https://youtu.be/GUxbM4EJrMo?si=jFVr8klkYPsygzSD)

The **DOXA Challenge notebook** can be found here: 🏆 [**DOXA Challenge 1**](https://github.com/UCLAIS/ml-tutorials-season-4/blob/main/doxa-challenges/challenge-1/getting-started.ipynb)

We will explain what this is in greater detail in the tutorial - you can start submitting your code mid reading week.

This is the end of the **Classical Machine Learning** section of the series. We will continute next half term on **Deep Learning** 🥳

Hope you have a great reading week! Please join our **WhatsApp** group chat through this [link](https://chat.whatsapp.com/JWEJn7OWvWE8MBfm2uSBhh).
