---
sidebar_position: 9
---

# 7: Recurrent Neural Networks

**Date: 6th December 2023**

ðŸ’¡ **Recurrent neural networks** (RNNs) are a type of artificial neural network (ANN) that are well-suited for processing **sequential data**, such as **time series** data or **natural language**. Unlike **feedforward neural networks**, where information flows in one direction, RNNs have **feedback loops** that allow them to retain information about previous inputs. This week we will be covering what RNNs are, how to train such models, the problems faced with RNN **backpropagation**, and introduce **variations of RNNs** such as the **long short-term memory (LSTM)** model. ðŸ’¡

You can access our **demonstration notebook** here: ðŸ“˜ [**Tutorial 7 Notebook**](https://github.com/UCLAIS/ml-tutorials-season-4/blob/main/week-7/rnn.ipynb)

You can access our **slides** here: ðŸ’» [**Tutorial 7 Slides**](https://www.canva.com/design/DAF0bkkh7uE/PlWo9_wcOAVhDKP_SdE56g/edit?utm_content=DAF0bkkh7uE&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton)
